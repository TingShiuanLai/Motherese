{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e32fafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***************************************************************\n",
      "Failed to import TensorFlow. Please note that TensorFlow is not installed by default when you install TFDS. This allows you to choose to install either `tf-nightly` or `tensorflow`. Please install the most recent version of TensorFlow, by following instructions at https://tensorflow.org/install.\n",
      "***************************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Failed to construct dataset \"librispeech\", builder_kwargs \"{'data_dir': None, 'config': 'lazy_decode'}\": No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py:442\u001b[39m, in \u001b[36mtry_reraise\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:218\u001b[39m, in \u001b[36mbuilder\u001b[39m\u001b[34m(name, try_gcs, **builder_kwargs)\u001b[39m\n\u001b[32m    215\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m py_utils.try_reraise(\n\u001b[32m    216\u001b[39m       prefix=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFailed to construct \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_dataset_repr()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    217\u001b[39m   ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbuilder_kwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pytype: disable=not-instantiable\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[38;5;66;03m# If neither the code nor the files are found, raise DatasetNotFoundError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:296\u001b[39m, in \u001b[36mbuilder_init.<locals>.decorator\u001b[39m\u001b[34m(function, dsbuilder, args, kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1502\u001b[39m, in \u001b[36mFileReaderBuilder.__init__\u001b[39m\u001b[34m(self, file_format, **kwargs)\u001b[39m\n\u001b[32m   1492\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Initializes an instance of FileReaderBuilder.\u001b[39;00m\n\u001b[32m   1493\u001b[39m \n\u001b[32m   1494\u001b[39m \u001b[33;03mCallers must pass arguments as keyword arguments.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1500\u001b[39m \u001b[33;03m  **kwargs: Arguments passed to `DatasetBuilder`.\u001b[39;00m\n\u001b[32m   1501\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[38;5;28mself\u001b[39m.info.set_file_format(file_format)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:296\u001b[39m, in \u001b[36mbuilder_init.<locals>.decorator\u001b[39m\u001b[34m(function, dsbuilder, args, kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:296\u001b[39m, in \u001b[36mDatasetBuilder.__init__\u001b[39m\u001b[34m(self, data_dir, config, version)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Use the code version (do not restore data)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m.initialize_from_bucket()\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.BLOCKED_VERSIONS \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:176\u001b[39m, in \u001b[36m_FunctionDecorator.__call__\u001b[39m\u001b[34m(self, function, instance, args, kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:509\u001b[39m, in \u001b[36mDatasetBuilder.info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    504\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    505\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mInfo should not been called before version has been defined. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    506\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mOtherwise, the created .info may not match the info version from \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    507\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mthe restored dataset.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    508\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(info, dataset_info.DatasetInfo):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\datasets\\librispeech\\librispeech_dataset_builder.py:75\u001b[39m, in \u001b[36mBuilder._info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_info\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     73\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset_info_from_configs(\n\u001b[32m     74\u001b[39m       features=tfds.features.FeaturesDict({\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mspeech\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mtfds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m              \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m              \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m              \u001b[49m\u001b[43mlazy_decode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuilder_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlazy_decode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m              \u001b[49m\u001b[43mfile_format\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mflac\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m          \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     81\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: tfds.features.Text(),\n\u001b[32m     82\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mspeaker_id\u001b[39m\u001b[33m\"\u001b[39m: np.int64,\n\u001b[32m     83\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mchapter_id\u001b[39m\u001b[33m\"\u001b[39m: np.int64,\n\u001b[32m     84\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: np.str_,\n\u001b[32m     85\u001b[39m       }),\n\u001b[32m     86\u001b[39m       supervised_keys=(\u001b[33m\"\u001b[39m\u001b[33mspeech\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     87\u001b[39m       homepage=_URL,\n\u001b[32m     88\u001b[39m       metadata=tfds.core.MetadataDict(\n\u001b[32m     89\u001b[39m           sample_rate=\u001b[32m16000\u001b[39m,\n\u001b[32m     90\u001b[39m       ),\n\u001b[32m     91\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\features\\audio_feature.py:267\u001b[39m, in \u001b[36mAudio.__init__\u001b[39m\u001b[34m(self, file_format, shape, dtype, sample_rate, encoding, doc, lazy_decode)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lazy_decode:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m   serialized_dtype = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstring\u001b[49m\n\u001b[32m    268\u001b[39m   serialized_shape = ()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\etils\\epy\\lazy_imports_utils.py:118\u001b[39m, in \u001b[36mLazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_module\u001b[49m, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\functools.py:1042\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[32m-> \u001b[39m\u001b[32m1042\u001b[39m     val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1043\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\etils\\epy\\lazy_imports_utils.py:79\u001b[39m, in \u001b[36mLazyModule._module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     78\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m _LOCK_PER_MODULE[\u001b[38;5;28mself\u001b[39m.module_name]:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtfds\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Enable lazy decoding for efficient loading\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ds, ds_info = \u001b[43mtfds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlibrispeech\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain_clean100\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or any other split\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuilder_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconfig\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlazy_decode\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_info\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:176\u001b[39m, in \u001b[36m_FunctionDecorator.__call__\u001b[39m\u001b[34m(self, function, instance, args, kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m metadata = \u001b[38;5;28mself\u001b[39m._start_call()\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    178\u001b[39m   metadata.mark_error()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:660\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs, file_format)\u001b[39m\n\u001b[32m    521\u001b[39m \u001b[38;5;129m@tfds_logging\u001b[39m.load()\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m    523\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    539\u001b[39m ):\n\u001b[32m    540\u001b[39m   \u001b[38;5;66;03m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[32m    541\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001b[39;00m\n\u001b[32m    542\u001b[39m \n\u001b[32m    543\u001b[39m \u001b[33;03m  `tfds.load` is a convenience method that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    658\u001b[39m \u001b[33;03m      Split-specific information is available in `ds_info.splits`.\u001b[39;00m\n\u001b[32m    659\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# fmt: skip\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m   dbuilder = \u001b[43m_fetch_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m      \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbuilder_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuilder_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtry_gcs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtry_gcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    666\u001b[39m   _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)\n\u001b[32m    668\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m as_dataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:495\u001b[39m, in \u001b[36m_fetch_builder\u001b[39m\u001b[34m(name, data_dir, builder_kwargs, try_gcs, file_format)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m   builder_kwargs[\u001b[33m'\u001b[39m\u001b[33mfile_format\u001b[39m\u001b[33m'\u001b[39m] = file_format\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtry_gcs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtry_gcs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbuilder_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:85\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:176\u001b[39m, in \u001b[36m_FunctionDecorator.__call__\u001b[39m\u001b[34m(self, function, instance, args, kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m metadata = \u001b[38;5;28mself\u001b[39m._start_call()\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    178\u001b[39m   metadata.mark_error()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:215\u001b[39m, in \u001b[36mbuilder\u001b[39m\u001b[34m(name, try_gcs, **builder_kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# If code exists and loading from files was skipped (e.g. files not found),\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[38;5;66;03m# load from the source code.\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m py_utils.try_reraise(\n\u001b[32m    216\u001b[39m       prefix=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFailed to construct \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_dataset_repr()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    217\u001b[39m   ):\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**builder_kwargs)  \u001b[38;5;66;03m# pytype: disable=not-instantiable\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[38;5;66;03m# If neither the code nor the files are found, raise DatasetNotFoundError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    160\u001b[39m     value = typ()\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py:444\u001b[39m, in \u001b[36mtry_reraise\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    442\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m444\u001b[39m   \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\10935\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py:411\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(e, prefix, suffix)\u001b[39m\n\u001b[32m    409\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    410\u001b[39m     exception = \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m exception \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;66;03m# Otherwise, modify the exception in-place\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(e.args) <= \u001b[32m1\u001b[39m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: Failed to construct dataset \"librispeech\", builder_kwargs \"{'data_dir': None, 'config': 'lazy_decode'}\": No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Enable lazy decoding for efficient loading\n",
    "ds, ds_info = tfds.load(\n",
    "    'librispeech',\n",
    "    split='train_clean100',  # or any other split\n",
    "    builder_kwargs={'config': 'lazy_decode'},\n",
    "    with_info=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c0dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f880d8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd75efee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
